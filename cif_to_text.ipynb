{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "# import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# from transformers import AdamW\n",
    "# from transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n",
    "from transformers import AutoTokenizer, T5EncoderModel, T5Tokenizer\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "\n",
    "pre_tokenizer = Whitespace()\n",
    "\n",
    "from llmprop_utils import *\n",
    "import pymatgen\n",
    "import pymatgen.core.structure \n",
    "from matminer.featurizers.site.fingerprint import CrystalNNFingerprint,AGNIFingerprints\n",
    "\n",
    "from llmprop_model import T5Predictor\n",
    "# pre-defined functions\n",
    "# from llmprop_model import T5Predictor\n",
    "from llmprop_utils import *\n",
    "from llmprop_dataset import *\n",
    "from llm_args_parse import *\n",
    "# set the random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import re\n",
    "import os\n",
    "from pymatgen.core.composition import Composition\n",
    "from tqdm import tqdm\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# parse Arguments\n",
    "args = ArgsParser()\n",
    "config = args.get_config()\n",
    "\n",
    "# set parameters\n",
    "batch_size = config.get('bs')\n",
    "max_length = config.get('max_len')\n",
    "learning_rate = config.get('lr')\n",
    "drop_rate = config.get('dr')\n",
    "epochs = config.get('epochs')\n",
    "warmup_steps = config.get('warmup_steps')\n",
    "preprocessing_strategy = config.get('preprocessing_strategy')\n",
    "tokenizer_name = config.get('tokenizer')\n",
    "pooling = config.get('pooling')\n",
    "scheduler_type = config.get('scheduler')\n",
    "normalizer_type = config.get('normalizer')\n",
    "property = config.get('property_name')\n",
    "optimizer_type = config.get('optimizer')\n",
    "task_name = config.get('task_name')\n",
    "train_data_path = config.get('train_data_path')\n",
    "valid_data_path = config.get('valid_data_path')\n",
    "test_data_path = config.get('test_data_path')\n",
    "all_data_path = config.get('all_data_path')\n",
    "\n",
    "# prepare the data\n",
    "train_data = pd.read_csv(train_data_path)\n",
    "valid_data = pd.read_csv(valid_data_path)\n",
    "test_data = pd.read_csv(test_data_path)\n",
    "\n",
    "all_data = pd.read_csv(all_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_non_zero_lengths(batch_inputs):\n",
    "    current_length = 0\n",
    "    for number in batch_inputs:\n",
    "        if number != 0:\n",
    "            # 如果当前数字非零，增加当前长度计数\n",
    "            current_length += 1\n",
    "    return current_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\deep\\GNN\\LLM-Prop-main\\llmprop_dataset.py:87: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:278.)\n",
      "  featurized_tensor = torch.tensor(featurized_list).float()\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# define the tokenizer\n",
    "if tokenizer_name == 't5_tokenizer': \n",
    "        # tokenizer = AutoTokenizer.from_pretrained(\"t5-small\")\n",
    "        tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-small\")\n",
    "        # tokenizer = AutoTokenizer.from_pretrained(\"google/mt5-small\")\n",
    "\n",
    "# add defined special tokens to the tokenizer\n",
    "if pooling == 'cls':\n",
    "        tokenizer.add_tokens([\"[CLS]\"])\n",
    "        \n",
    "all_dataloader = create_dataloaders(\n",
    "        tokenizer, \n",
    "        all_data, \n",
    "        max_length, \n",
    "        batch_size, \n",
    "        property_value=property, \n",
    "        pooling=pooling\n",
    "    )\n",
    "\n",
    "inputs_all = []\n",
    "for batch in all_dataloader:\n",
    "        batch_inputs, _, _ = tuple(b for b in batch)\n",
    "        inputs_all.append(batch_inputs)\n",
    "\n",
    "# 使用列表解析和torch.cat函数对列表中的tensor进行拼接\n",
    "concatenated_tensor = torch.cat(inputs_all, dim=0)\n",
    "\n",
    "middle_field = train_data_path.split('/')[1]\n",
    "\n",
    "count_num = [count_non_zero_lengths(i) for i in concatenated_tensor]\n",
    "# plt.figure(figsize=(12, 9))  \n",
    "plt.bar(range(len(count_num)), count_num)\n",
    "plt.xlabel(f'{middle_field} Datasets Numbers')\n",
    "plt.ylabel(f'{middle_field} Structure Description Tokens Length')\n",
    "plt.title(f'{middle_field} Tokens Length')\n",
    "plt.savefig(f'./plots/{middle_field}_tokens_length_plot.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5Predictor(\n",
       "  (embedding_layer): Embedding(32128, 512)\n",
       "  (encoders): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 6)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-7): 7 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (fc_mat2vec): Linear(in_features=24, out_features=512, bias=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (linear_layer): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=512, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "\n",
    "base_model_output_size = 512\n",
    "base_model = T5EncoderModel.from_pretrained(\"google/flan-t5-small\")\n",
    "model = T5Predictor(base_model, base_model_output_size, drop_rate=drop_rate, pooling=pooling)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nonmetal'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "id2label = {0: \"metal\", 1: \"nonmetal\"}\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/MatBERT\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"google/MatBERT\")\n",
    "\n",
    "description = \"BN is Boron Nitride structured and crystallizes in the hexagonal P6_3/mmc space group. B(1) is bonded in a trigonal planar geometry to three equivalent N(1) atoms. All B(1)–N(1) bond lengths are 1.45 Å. N(1) is bonded in a trigonal planar geometry to three equivalent B(1) atoms.\"\n",
    "inputs = tokenizer(description, return_tensors=\"pt\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model(**inputs).logits\n",
    "predicted_class = id2label[logits.argmax().item()]\n",
    "predicted_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CompositionError(Exception):\n",
    "    \"\"\"Exception class for composition errors\"\"\"\n",
    "    pass\n",
    "\n",
    "def get_sym_dict(f, factor):\n",
    "    sym_dict = collections.defaultdict(float)\n",
    "    # compile regex for speedup\n",
    "    regex = r\"([A-Z][a-z]*)\\s*([-*\\.\\d]*)\"\n",
    "    r = re.compile(regex)\n",
    "    for m in re.finditer(r, f):\n",
    "        el = m.group(1)\n",
    "        amt = 1\n",
    "        if m.group(2).strip() != \"\":\n",
    "            amt = float(m.group(2))\n",
    "        sym_dict[el] += amt * factor\n",
    "        f = f.replace(m.group(), \"\", 1)\n",
    "    if f.strip():\n",
    "        raise CompositionError(f'{f} is an invalid formula!')\n",
    "    return sym_dict\n",
    "\n",
    "\n",
    "def parse_formula(formula):\n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "        formula: str\n",
    "            A string formula, e.g. Fe2O3, Li3Fe2(PO4)3.\n",
    "    Return\n",
    "    ----------\n",
    "        sym_dict: dict\n",
    "            A dictionary recording the composition of that formula.\n",
    "    Notes\n",
    "    ----------\n",
    "        In the case of Metallofullerene formula (e.g. Y3N@C80),\n",
    "        the @ mark will be dropped and passed to parser.\n",
    "    '''\n",
    "    # for Metallofullerene like \"Y3N@C80\"\n",
    "    formula = formula.replace('@', '')\n",
    "    formula = formula.replace('[', '(')\n",
    "    formula = formula.replace(']', ')')\n",
    "    # compile regex for speedup\n",
    "    regex = r\"\\(([^\\(\\)]+)\\)\\s*([\\.\\d]*)\"\n",
    "    r = re.compile(regex)\n",
    "    m = re.search(r, formula)\n",
    "    if m:\n",
    "        factor = 1\n",
    "        if m.group(2) != \"\":\n",
    "            factor = float(m.group(2))\n",
    "        unit_sym_dict = get_sym_dict(m.group(1), factor)\n",
    "        expanded_sym = \"\".join([\"{}{}\".format(el, amt)\n",
    "                                for el, amt in unit_sym_dict.items()])\n",
    "        expanded_formula = formula.replace(m.group(), expanded_sym)\n",
    "        return parse_formula(expanded_formula)\n",
    "    sym_dict = get_sym_dict(formula, 1)\n",
    "    return sym_dict\n",
    "\n",
    "\n",
    "def _element_composition(formula):\n",
    "    elmap = parse_formula(formula)\n",
    "    elamt = {}\n",
    "    natoms = 0\n",
    "    for k, v in elmap.items():\n",
    "        if abs(v) >= 1e-6:\n",
    "            elamt[k] = v\n",
    "            natoms += abs(v)\n",
    "    return elamt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating EDM: 100%|██████████| 1265/1265 [00:00<00:00, 105426.40formulae/s]\n"
     ]
    }
   ],
   "source": [
    "# crabnet\n",
    "\n",
    "def get_edm(all_data, n_elements=16, verbose=True, scale=True, data_type_torch = torch.float32):\n",
    "    \"\"\"\n",
    "    annotations\n",
    "    \"\"\"\n",
    "    all_symbols = ['H', 'He', 'Li', 'Be', 'B', 'C', 'N', 'O', 'F', 'Ne', 'Na',\n",
    "                    'Mg', 'Al', 'Si', 'P', 'S', 'Cl', 'Ar', 'K', 'Ca', 'Sc',\n",
    "                    'Ti', 'V', 'Cr', 'Mn', 'Fe', 'Co', 'Ni', 'Cu', 'Zn', 'Ga',\n",
    "                    'Ge', 'As', 'Se', 'Br', 'Kr', 'Rb', 'Sr', 'Y', 'Zr', 'Nb',\n",
    "                    'Mo', 'Tc', 'Ru', 'Rh', 'Pd', 'Ag', 'Cd', 'In', 'Sn', 'Sb',\n",
    "                    'Te', 'I', 'Xe', 'Cs', 'Ba', 'La', 'Ce', 'Pr', 'Nd', 'Pm',\n",
    "                    'Sm', 'Eu', 'Gd', 'Tb', 'Dy', 'Ho', 'Er', 'Tm', 'Yb', 'Lu',\n",
    "                    'Hf', 'Ta', 'W', 'Re', 'Os', 'Ir', 'Pt', 'Au', 'Hg', 'Tl',\n",
    "                    'Pb', 'Bi', 'Po', 'At', 'Rn', 'Fr', 'Ra', 'Ac', 'Th', 'Pa',\n",
    "                    'U', 'Np', 'Pu', 'Am', 'Cm', 'Bk', 'Cf', 'Es', 'Fm', 'Md',\n",
    "                    'No', 'Lr', 'Rf', 'Db', 'Sg', 'Bh', 'Hs', 'Mt', 'Ds', 'Rg',\n",
    "                    'Cn', 'Nh', 'Fl', 'Mc', 'Lv', 'Ts', 'Og']\n",
    "    \n",
    "    df = all_data\n",
    "    df = df.dropna(how='any')\n",
    "    df['count'] = [len(_element_composition(form)) for form in df['formula']]\n",
    "    # df = df.groupby(by='formula').mean().reset_index()\n",
    "    list_ohm = [OrderedDict(_element_composition(form))\n",
    "                    for form in df['formula']]\n",
    "    list_ohm = [OrderedDict(sorted(mat.items(), key=lambda x:-x[1]))\n",
    "                    for mat in list_ohm]\n",
    "    data_type_np = np.float32\n",
    "    edm_array = np.zeros(shape=(len(list_ohm),\n",
    "                                    n_elements,\n",
    "                                    len(all_symbols)+1),\n",
    "                            dtype=data_type_np)\n",
    "    elem_num = np.zeros(shape=(len(list_ohm), n_elements), dtype=data_type_np)\n",
    "    elem_frac = np.zeros(shape=(len(list_ohm), n_elements), dtype=data_type_np)\n",
    "    for i, comp in enumerate(tqdm(list_ohm,\n",
    "                                    desc=\"Generating EDM\",\n",
    "                                    unit=\"formulae\",\n",
    "                                    disable=not verbose)):\n",
    "            for j, (elem, count) in enumerate(list_ohm[i].items()):\n",
    "                if j == n_elements:\n",
    "                    # Truncate EDM representation to n_elements\n",
    "                    break\n",
    "                try:\n",
    "                    edm_array[i, j, all_symbols.index(elem) + 1] = count\n",
    "                    elem_num[i, j] = all_symbols.index(elem) + 1\n",
    "                except ValueError:\n",
    "                    print(f'skipping composition {comp}')   \n",
    "    scale = True\n",
    "    if scale: \n",
    "            # Normalize element fractions within the compound\n",
    "            for i in range(edm_array.shape[0]):\n",
    "                frac = (edm_array[i, :, :].sum(axis=-1)\n",
    "                        / (edm_array[i, :, :].sum(axis=-1)).sum())\n",
    "                elem_frac[i, :] = frac\n",
    "    else:\n",
    "            # Do not normalize element fractions, even for single-element compounds\n",
    "            for i in range(edm_array.shape[0]):\n",
    "                frac = edm_array[i, :, :].sum(axis=-1)\n",
    "                elem_frac[i, :] = frac\n",
    "    if n_elements == 16:\n",
    "            n_elements = np.max(np.sum(elem_frac > 0, axis=1, keepdims=True))\n",
    "            elem_num = elem_num[:, :n_elements]\n",
    "            elem_frac = elem_frac[:, :n_elements]\n",
    "    elem_num = elem_num.reshape(elem_num.shape[0], elem_num.shape[1], 1)\n",
    "    elem_frac = elem_frac.reshape(elem_frac.shape[0], elem_frac.shape[1], 1)\n",
    "    out = torch.tensor(np.concatenate((elem_num, elem_frac), axis=1))\n",
    "    src, frac = out.squeeze(-1).chunk(2, dim=1)\n",
    "    src = src.to(\n",
    "                dtype=torch.long,\n",
    "                non_blocking=True)\n",
    "    frac = frac.to(\n",
    "                dtype=data_type_torch,\n",
    "                non_blocking=True)\n",
    "    mask = frac \n",
    "    mask[mask != 0] = 1\n",
    "    return src,frac,mask\n",
    "\n",
    "src,frac,mask = get_edm(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from encoder_model import Encoder\n",
    "encoder = Encoder()\n",
    "x_src = encoder(src, frac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5000, 0.5000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000],\n",
       "        ...,\n",
       "        [0.6000, 0.2000, 0.2000, 0.0000, 0.0000],\n",
       "        [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.6667, 0.3333, 0.0000, 0.0000, 0.0000]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载T5模型和tokenizer\n",
    "base_model = T5EncoderModel.from_pretrained(\"google/flan-t5-small\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-small\")\n",
    "\n",
    "# create dataloaders\n",
    "train_dataloader = create_dataloaders(\n",
    "        tokenizer, \n",
    "        train_data, \n",
    "        max_length, \n",
    "        batch_size, \n",
    "        property_value=property, \n",
    "        pooling=pooling, \n",
    "        normalize=True, \n",
    "        normalizer=normalizer_type\n",
    "    )\n",
    "\n",
    "for step, batch in enumerate(train_dataloader):\n",
    "            batch_inputs, batch_masks, batch_labels, batch_norm_labels = tuple(b.to(device) for b in batch)\n",
    "            input_embedding, predictions = model(batch_inputs, batch_masks )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_embedding, predictions = model(batch_inputs, batch_masks )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 7, 512])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 加载T5模型和tokenizer\n",
    "base_model = T5EncoderModel.from_pretrained(\"google/flan-t5-small\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-small\")\n",
    "\n",
    "# 获取Embedding层\n",
    "embedding_layer = base_model.shared\n",
    "\n",
    "# 构造输入文本\n",
    "input_text = \"Hello, how are you?\"\n",
    "input_ids = tokenizer(input_text, return_tensors=\"pt\")[\"input_ids\"]\n",
    "\n",
    "# 对Embedding层执行forward()操作\n",
    "embedding_output = embedding_layer(input_ids)\n",
    "\n",
    "\n",
    "\n",
    "# 对Embedding层执行forward()操作，获取最后一层的输出\n",
    "with torch.no_grad():\n",
    "    model_output = base_model(input_ids)\n",
    "\n",
    "# 获取最后一层的输出\n",
    "last_hidden_state = model_output.last_hidden_state\n",
    "\n",
    "print(last_hidden_state.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaseModelOutputWithPastAndCrossAttentions(last_hidden_state=tensor([[[-0.0542, -0.2019, -0.0090,  ..., -0.0026, -0.1892, -0.0932],\n",
      "         [-0.0707, -0.0110,  0.0484,  ...,  0.2682,  0.0296, -0.0810],\n",
      "         [-0.0258, -0.1898,  0.0504,  ...,  0.1895, -0.2146, -0.1730],\n",
      "         ...,\n",
      "         [ 0.0842,  0.0102, -0.3535,  ..., -0.3378,  0.0366, -0.1812],\n",
      "         [-0.1450, -0.2351, -0.1390,  ..., -0.1920,  0.2845, -0.1519],\n",
      "         [ 0.0303,  0.0811, -0.1199,  ..., -0.1470,  0.0234, -0.1669]]],\n",
      "       grad_fn=<MulBackward0>), past_key_values=None, hidden_states=None, attentions=None, cross_attentions=None)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import T5EncoderModel, AutoTokenizer\n",
    "\n",
    "# 加载T5模型和tokenizer\n",
    "base_model = T5EncoderModel.from_pretrained(\"google/flan-t5-small\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-small\")\n",
    "\n",
    "# 获取Embedding层\n",
    "embedding_layer = base_model.shared\n",
    "\n",
    "# 构造输入文本\n",
    "input_text = \"Hello, how are you?\"\n",
    "input_ids = tokenizer(input_text, return_tensors=\"pt\")[\"input_ids\"]\n",
    "\n",
    "# 对Embedding层执行forward()操作\n",
    "embedding_output = embedding_layer(input_ids)\n",
    "\n",
    "# 拼接自定义的embedding features\n",
    "custom_features = torch.randn(1, 7, 512)  # 假设自定义的embedding features为512维\n",
    "combined_features = torch.cat((embedding_output, custom_features), dim=1)\n",
    "\n",
    "# 继续执行base_model后面的网络layers\n",
    "# outputs = base_model(inputs_embeds=combined_features)\n",
    "outputs = base_model.encoder(inputs_embeds=combined_features)\n",
    "\n",
    "# 输出模型的结果\n",
    "print(outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5EncoderModel(\n",
       "  (shared): Embedding(32128, 512)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 6)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-7): 7 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "blocks = base_model.encoder.block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5Block(\n",
       "  (layer): ModuleList(\n",
       "    (0): T5LayerSelfAttention(\n",
       "      (SelfAttention): T5Attention(\n",
       "        (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "        (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "        (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "        (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "        (relative_attention_bias): Embedding(32, 6)\n",
       "      )\n",
       "      (layer_norm): T5LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): T5LayerFF(\n",
       "      (DenseReluDense): T5DenseGatedActDense(\n",
       "        (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
       "        (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
       "        (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (act): NewGELUActivation()\n",
       "      )\n",
       "      (layer_norm): T5LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blocks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5Block(\n",
       "  (layer): ModuleList(\n",
       "    (0): T5LayerSelfAttention(\n",
       "      (SelfAttention): T5Attention(\n",
       "        (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "        (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "        (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "        (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "      )\n",
       "      (layer_norm): T5LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): T5LayerFF(\n",
       "      (DenseReluDense): T5DenseGatedActDense(\n",
       "        (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
       "        (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
       "        (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (act): NewGELUActivation()\n",
       "      )\n",
       "      (layer_norm): T5LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blocks[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'T5Attention' object has no attribute 'config'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32md:\\deep\\GNN\\LLM-Prop-main\\cif_to_text.ipynb Cell 24\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/deep/GNN/LLM-Prop-main/cif_to_text.ipynb#Y105sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m origin_att \u001b[39m=\u001b[39m blocks[\u001b[39m3\u001b[39m]\u001b[39m.\u001b[39mlayer[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mSelfAttention\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/deep/GNN/LLM-Prop-main/cif_to_text.ipynb#Y105sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m origin_att\u001b[39m.\u001b[39;49mconfig\n",
      "File \u001b[1;32md:\\ProgramData\\envs\\LLM\\lib\\site-packages\\torch\\nn\\modules\\module.py:1688\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1686\u001b[0m     \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m modules:\n\u001b[0;32m   1687\u001b[0m         \u001b[39mreturn\u001b[39;00m modules[name]\n\u001b[1;32m-> 1688\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'T5Attention' object has no attribute 'config'"
     ]
    }
   ],
   "source": [
    "origin_att = blocks[3].layer[0].SelfAttention\n",
    "origin_att.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 6,  2,  0,  8],\n",
      "        [ 0,  6, 10,  4]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_scatter import scatter\n",
    "\n",
    "# 创建一个输入张量\n",
    "src = torch.tensor([[1, 2, 3, 4], [5, 6, 7, 8]])  # 2个节点，每个节点有4个特征\n",
    "\n",
    "# 创建一个索引张量，用于指定每个节点的特征应该被聚合到哪里\n",
    "index = torch.tensor([[0, 0, 1, 1], [0, 1, 1, 0]])  # 每个节点的特征应该被聚合到的目标节点\n",
    "\n",
    "# 执行scatter操作，将src中的特征按照index指定的规则聚合\n",
    "out = scatter(src, index, dim=0, reduce='sum')  # 在dim=0维度上按照sum规则聚合\n",
    "\n",
    "print(out)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 7])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 7, 512])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建一个迭代器\n",
    "data_iter = iter(all_dataloader)\n",
    "\n",
    "# 获取下一个批次的数据\n",
    "batch = next(data_iter)\n",
    "\n",
    "batch_inputs, batch_masks, batch_labels  = batch\n",
    "# 在这里，input_data是输入数据，target_data是目标数据\n",
    "# 您可以根据您的数据结构来访问和处理input_data和target_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pymatgen_deserialize_dicts(dicts, to_unit_cell: bool = False):\n",
    "        s = pymatgen.core.structure.Structure.from_dict(dicts)\n",
    "        if to_unit_cell:\n",
    "                for site in s.sites:\n",
    "                    site.to_unit_cell(in_place=True)\n",
    "        return s\n",
    "\n",
    "\n",
    "def featurize_structure(structure, max_atoms):\n",
    "        CrystalNNFinger = []\n",
    "        mask = []\n",
    "        cnnfp = AGNIFingerprints(directions=[\"x\", \"y\", \"z\"])\n",
    "        structure = pymatgen_deserialize_dicts(structure)\n",
    "        for i in range(len(structure)):\n",
    "            try:\n",
    "                sites_feature = np.array(cnnfp.featurize(structure, i))\n",
    "                mask.append(1)\n",
    "            except:\n",
    "                sites_feature = np.zeros((24,))\n",
    "                mask.append(0)\n",
    "            CrystalNNFinger.append(sites_feature)\n",
    "            \n",
    "        if len(structure) < max_atoms:\n",
    "            diff = max_atoms - len(structure)\n",
    "            for i in range(diff):\n",
    "                CrystalNNFinger.append(np.zeros((24,)))\n",
    "                mask.append(0)\n",
    "        return CrystalNNFinger,mask\n",
    "    \n",
    "    \n",
    "def cal_max_atoms(structures):\n",
    "    structures_pymatgen = [pymatgen_deserialize_dicts(eval(s)) for s in structures]\n",
    "    max_atoms = max([len(structure) for structure in structures_pymatgen])\n",
    "    return max_atoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "structures = all_data['structure'].tolist()\n",
    "max_atoms = cal_max_atoms(structures)\n",
    "featurized_list = []\n",
    "mask_list = []\n",
    "for s in structures:\n",
    "    fea,mas = featurize_structure(eval(s), max_atoms)\n",
    "    featurized_list.append(fea)\n",
    "    mask_list.append(mas)\n",
    "# featurized_list = [featurize_structure(eval(s), max_atoms)[0] for s in structures]\n",
    "featurized_tensor = torch.tensor(featurized_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(mask_list)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([636, 35, 24])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structure = pymatgen_deserialize_dicts(eval(structures[9]))\n",
    "len(structure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 6,  2,  0,  8],\n",
      "        [ 0,  6, 10,  4]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_scatter import scatter\n",
    "\n",
    "# 创建一个输入张量\n",
    "src = torch.tensor([[1, 2, 3, 4], [5, 6, 7, 8]])  # 2个节点，每个节点有4个特征\n",
    "\n",
    "# 创建一个索引张量，用于指定每个节点的特征应该被聚合到哪里\n",
    "index = torch.tensor([[0, 0, 1, 1], [0, 1, 1, 0]])  # 每个节点的特征应该被聚合到的目标节点\n",
    "\n",
    "# 执行scatter操作，将src中的特征按照index指定的规则聚合\n",
    "out = scatter(src, index, dim=0, reduce='sum')  # 在dim=0维度上按照sum规则聚合\n",
    "\n",
    "print(out)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[  784,  8440,   134,   908,     3,   476,   254,    40,   519,    19,\n",
       "          27042,     3,    17,  3723,   322,  1599,    18,  2376, 14039,    11,\n",
       "           6884,    40,  1737,     7,    16,     8,  7414, 11005,   447,   205,\n",
       "          15896,    51,   628,   563,     5,    37,  1809,    19,   192,    18,\n",
       "          11619,    11,     3,  6848,    13,    80,     3,   476,   254,    40,\n",
       "            519,  4228,     3,  9442,    16,     8, 17482,     6,  8014,  8925,\n",
       "           2212,     5,     3,   476, 14296,   519,  1220,    19,     3, 25357,\n",
       "             12,  1296,  7072,  4779,   599,  4347,  7318,   536,     2,     3,\n",
       "          10432,     7,    12,   607,  3023,    18, 22473,     3,   476,   254,\n",
       "             40,   948,     3,    32,    75,    17,     9,    88,  3515,     5,\n",
       "            432,     3,   476, 14296,    18,   254,    40,   599,  4347,  7318,\n",
       "           6235,  2475,     7,    33,     3, 22724,  3647,     3,     2,     5,\n",
       "           4779,   599,  4347,  7318,   536,     2,    19,     3, 25357,    16,\n",
       "             46,   301,    18,  6489, 23898,    12,   192,  7072,     3,   476,\n",
       "          14296,   519,  1220,     3, 10432,     7,     5,     1,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0],\n",
       "         [  784,  8440,   134,   908,   283,   122,   357,   134,    23,   667,\n",
       "            591,  6884,    40,  1737,     7,    16,     8,     3,    17,    15,\n",
       "           5031,  9533,   276,   591,    87,    51,   635,   628,   563,     5,\n",
       "             37,  1809,    19,   192,    18, 11619,    11,     3,  6848,    13,\n",
       "             80,   283,   122,   357,   134,    23,   667,   591,  4228,     3,\n",
       "           9442,    16,     8, 17482,     6,  8014,  8925,  2212,     5,   283,\n",
       "            122, 14296,   357,  1220,    19,     3, 25357,    16,     3,     9,\n",
       "            712,    18, 18414, 23898,    12,    80,   411, 14296,   357,     2,\n",
       "              3, 10432,     5,    37,   283,   122, 14296,    18,   667, 14296,\n",
       "           6235,  2475,    19,     3, 16253,  5176,     3,     2,     5,   925,\n",
       "          14296,   591,  1220,    19,     3, 25357,    12,   192,  7072,   411,\n",
       "          14296,   357,     2,    11,   662,   411,   599,  4482,  7318,   357,\n",
       "              2,     3, 10432,     7,    12,   607,  2752,    18, 22473,   925,\n",
       "            667,   948,     3,    32,    75,    17,     9,    88,  3515,     5,\n",
       "             37,  2752,    18, 22473,     3,    32,    75,    17,     9,    88,\n",
       "           3515,    33,    59, 20382,    15,    26,     5,  2867,   925, 14296,\n",
       "             18,   667, 14296,  6235,  2475,     7,    33,     3, 18596,  2658,\n",
       "              3,     2,     5,   432,   925, 14296,    18,   667,   599,  4482,\n",
       "           7318,  6235,  2475,     7,    33,     3, 18596,  3647,     3,     2,\n",
       "              5,   290,    33,   386,    16,    15,  1169, 15592,   411,   357,\n",
       "              2,  1471,     5,    86,     8,   166,   411,   357,     2,   353,\n",
       "              6,   411, 14296,   357,     2,    19,     3, 25357,    16,     3,\n",
       "              9, 13080, 23898,    12,    80,   283,   122, 14296,   357,  1220,\n",
       "             11,    80,   925, 14296,   591,  1220,     3, 10432,     5,    86,\n",
       "              8,   511,   411,   357,     2,   353,     6,   411, 16426,   357,\n",
       "              2,    19,     3, 25357,    16,     1]]),\n",
       " tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]),\n",
       " tensor([  68.8906, 1604.0383], dtype=torch.float64),\n",
       " tensor([-0.3331, 10.5475], dtype=torch.float64)]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 256])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 256])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_masks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_masks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dft one fold 811"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set saved with 3763 rows.\n",
      "Validation set saved with 470 rows.\n",
      "Test set saved with 471 rows.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "name = 'jarvis_dft_3d_dfpt_piezo_max_dielectric'\n",
    "file_name = 'dfpt_piezo_max_dielectric'\n",
    "\n",
    "# 读取原始CSV文件\n",
    "df = pd.read_csv(f'data/{name}/{file_name}.csv')\n",
    "\n",
    "# 计算分割点\n",
    "total_data = len(df)\n",
    "train_size = int(total_data * 0.8)\n",
    "val_size = int(total_data * 0.1)\n",
    "\n",
    "# 分割数据集\n",
    "train_df, test_val_df = train_test_split(df, test_size=(1 - 0.8), random_state=42)\n",
    "\n",
    "# 进一步分割验证集和测试集，这里我们假设验证集和测试集各占剩余数据的一半\n",
    "val_df, test_df = train_test_split(test_val_df, test_size=0.5, random_state=42)\n",
    "\n",
    "# 保存分割后的数据集到CSV文件\n",
    "train_df.to_csv(f'data/{name}/{file_name}_train.csv', index=False)\n",
    "val_df.to_csv(f'data/{name}/{file_name}_valid.csv', index=False)\n",
    "test_df.to_csv(f'data/{name}/{file_name}_test.csv', index=False)\n",
    "\n",
    "print(f\"Training set saved with {train_size} rows.\")\n",
    "print(f\"Validation set saved with {len(val_df)} rows.\")\n",
    "print(f\"Test set saved with {len(test_df)} rows.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## one fold split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set saved with 9448 rows.\n",
      "Validation set saved with 769 rows.\n",
      "Test set saved with 770 rows.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "name = 'allmatbench_log_gvrh'\n",
    "file_name = 'matbench_log_gvrh'\n",
    "\n",
    "# 读取原始CSV文件\n",
    "df = pd.read_csv(f'data/{name}/{file_name}.csv')\n",
    "\n",
    "# 计算分割点\n",
    "total_data = len(df)\n",
    "train_size = int(total_data * 0.86)\n",
    "val_size = int(total_data * 0.07)\n",
    "\n",
    "# 分割数据集\n",
    "train_df, test_val_df = train_test_split(df, test_size=(1 - 0.86), random_state=42)\n",
    "\n",
    "# 进一步分割验证集和测试集，这里我们假设验证集和测试集各占剩余数据的一半\n",
    "val_df, test_df = train_test_split(test_val_df, test_size=0.5, random_state=42)\n",
    "\n",
    "# 保存分割后的数据集到CSV文件\n",
    "train_df.to_csv(f'data/{name}/{file_name}_train.csv', index=False)\n",
    "val_df.to_csv(f'data/{name}/{file_name}_valid.csv', index=False)\n",
    "test_df.to_csv(f'data/{name}/{file_name}_test.csv', index=False)\n",
    "\n",
    "print(f\"Training set saved with {train_size} rows.\")\n",
    "print(f\"Validation set saved with {len(val_df)} rows.\")\n",
    "print(f\"Test set saved with {len(test_df)} rows.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## five fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.86"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "import os\n",
    "\n",
    "# 读取原始CSV文件\n",
    "df = pd.read_csv('matbench_jdft2d.csv')\n",
    "\n",
    "# 初始化KFold\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# 创建文件夹来保存分割后的CSV文件\n",
    "output_dir = 'matbench_jdft2d_splits'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# 初始化计数器\n",
    "fold_counter = 1\n",
    "\n",
    "# 对于每一折\n",
    "for train_index, val_index in kf.split(df):\n",
    "    # 创建训练集和验证集的DataFrame\n",
    "    train_df = df.iloc[train_index]\n",
    "    val_df = df.iloc[val_index]\n",
    "\n",
    "    # 保存训练集和验证集到CSV文件\n",
    "    train_file_path = os.path.join(output_dir, f'matbench_jdft2d_train_{fold_counter}.csv')\n",
    "    val_file_path = os.path.join(output_dir, f'matbench_jdft2d_valid_{fold_counter}.csv')\n",
    "    \n",
    "    train_df.to_csv(train_file_path, index=False)\n",
    "    val_df.to_csv(val_file_path, index=False)\n",
    "\n",
    "    # 更新计数器\n",
    "    fold_counter += 1\n",
    "\n",
    "print(\"5-fold cross-validation splits have been created and saved to CSV files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All CSV files have been merged and saved to matbench_log_gvrh.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# 文件夹路径，假设CSV文件都在这里\n",
    "# folder_path = 'data/matbench_dielectric/'  # 替换为您的CSV文件所在的文件夹路径\n",
    "folder_path = 'all/'\n",
    "\n",
    "# 读取所有CSV文件并将它们合并到一个DataFrame\n",
    "all_data = pd.DataFrame()\n",
    "\n",
    "for i in range(3):\n",
    "    file_name = f'matbench_log_gvrh-{i}.csv'\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "    \n",
    "    # 读取CSV文件\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # 如果是第一个文件，保留所有列；否则，只保留指定的列\n",
    "    if i == 0:\n",
    "        # 保留所有列\n",
    "        all_data = df\n",
    "    else:\n",
    "        # 只保留指定的列，例如：['index', 'formula', 'structure', 'description', 'n']\n",
    "        selected_columns = ['index', 'formula', 'structure', 'description', 'log10(G_VRH)']\n",
    "        df_selected = df[selected_columns]\n",
    "        all_data = pd.concat([all_data, df_selected], ignore_index=True)\n",
    "        \n",
    "# 重新设置index列顺序\n",
    "all_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# 保存合并后的DataFrame到一个新的CSV文件\n",
    "merged_file_name = 'matbench_log_gvrh.csv'\n",
    "all_data.to_csv(merged_file_name, index=False)\n",
    "\n",
    "print(f'All CSV files have been merged and saved to {merged_file_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 读取CSV文件\n",
    "df = pd.read_csv('data/allmatbench_log_gvrh/matbench_log_gvrh.csv')\n",
    "\n",
    "# 重置index列\n",
    "df['index'] = df.index\n",
    "\n",
    "# 保存到新的CSV文件\n",
    "df.to_csv('./matbench_log_gvrh_merged.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## delete the blank row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered CSV file saved to matbench_log_gvrh_filtered.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "# CSV文件路径\n",
    "csv_file_path = 'matbench_log_gvrh.csv'\n",
    "file_path = 'matbench_log_gvrh'\n",
    "all_path = os.path.join('data/allmatbench_log_gvrh/', csv_file_path)\n",
    "# 读取CSV文件\n",
    "df = pd.read_csv(all_path)\n",
    "\n",
    "# 过滤掉description列包含空白或空字符的行\n",
    "# 这里使用str.strip()来移除字符串两端的空白字符，然后检查是否为空\n",
    "# str.contains()用于检查字符串是否包含特定的模式，这里我们检查是否包含任意非空白字符\n",
    "filtered_df = df[(df['description'].str.strip().str.contains(r'\\S', na=False))]\n",
    "\n",
    "# 保存过滤后的DataFrame到新的CSV文件\n",
    "filtered_csv_file_path = f'{file_path}_filtered.csv'\n",
    "save_path = os.path.join(f'data/all{file_path}/', filtered_csv_file_path)\n",
    "filtered_df.to_csv(save_path, index=False)\n",
    "\n",
    "print(f\"Filtered CSV file saved to {filtered_csv_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
